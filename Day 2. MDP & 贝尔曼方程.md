# MDP 1 Background of MDP:

## Several basic definitions:

(1)Random Variable  
(2)Stochastic Process  //stochatic: (过程与系统上) 随机的  
(3)Markov Chain/Process:具有Markov Property的随机过程  P（St+1 | St, St-1, ..., S1) = P(St+1 | St)是Markov Property的描述  
(4)State Space Model：（HMM, Kalman Filter, Particle Filter）Markov Chain  
(5)Markov Reward Process: Markov Chain + Reward  
(6)Markov Decision Process: Markov Chain + Reward + Action  

*S* ：state set  
*A* ：action set $\forall s \in S$, $A(s) \longrightarrow At$  
*R* : reward set $\longrightarrow Rt, R_{t+1}$


# MDP 2 Dynamic Property of MDP

## Definitions:

(1)MC : S  
(2)MRP : S, R  
(3)MDP : S, A(s), R  



